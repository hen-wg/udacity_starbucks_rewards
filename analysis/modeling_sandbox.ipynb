{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Modeling Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# read parquet files into dataframes\n",
    "offer_df = pd.read_parquet('data/offer_df.parquet')\n",
    "offer_complete_df = pd.read_parquet('data/offer_complete_df.parquet')\n",
    "transaction_df = pd.read_parquet('data/transaction_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>time</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>days_as_member</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>reward</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>email</th>\n",
       "      <th>mobile</th>\n",
       "      <th>social</th>\n",
       "      <th>web</th>\n",
       "      <th>offer_completed</th>\n",
       "      <th>offer_viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19018</th>\n",
       "      <td>6de6f7e081af455886287068f1b40419</td>\n",
       "      <td>fafdcd668e3743c1bb461111dcafc2a4</td>\n",
       "      <td>2778</td>\n",
       "      <td>125.0</td>\n",
       "      <td>335000.0</td>\n",
       "      <td>9450.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3283</th>\n",
       "      <td>1359818aa5bc4becaad9c18df5dbf776</td>\n",
       "      <td>ae264e3637204a6fb9bb56bc8210ddfd</td>\n",
       "      <td>1758</td>\n",
       "      <td>156.0</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>5700.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37871</th>\n",
       "      <td>db564686d31c48e4b35a4ee0ce50f824</td>\n",
       "      <td>2298d6c36e964ae4a3e7e9706d1fb8c2</td>\n",
       "      <td>822</td>\n",
       "      <td>126.0</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>3592.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28430</th>\n",
       "      <td>a2f9b5fcc34649cf82d76d221024a644</td>\n",
       "      <td>0b1e1539f2cc45b7b9fa7c272da2e1d7</td>\n",
       "      <td>1290</td>\n",
       "      <td>174.0</td>\n",
       "      <td>174000.0</td>\n",
       "      <td>5721.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43616</th>\n",
       "      <td>fca0cfd25f0f4d489137d3e4bd863e20</td>\n",
       "      <td>2906b810c7d4411798c6938adc9daaa5</td>\n",
       "      <td>2244</td>\n",
       "      <td>170.0</td>\n",
       "      <td>230000.0</td>\n",
       "      <td>12090.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                user_id                          offer_id  \\\n",
       "19018  6de6f7e081af455886287068f1b40419  fafdcd668e3743c1bb461111dcafc2a4   \n",
       "3283   1359818aa5bc4becaad9c18df5dbf776  ae264e3637204a6fb9bb56bc8210ddfd   \n",
       "37871  db564686d31c48e4b35a4ee0ce50f824  2298d6c36e964ae4a3e7e9706d1fb8c2   \n",
       "28430  a2f9b5fcc34649cf82d76d221024a644  0b1e1539f2cc45b7b9fa7c272da2e1d7   \n",
       "43616  fca0cfd25f0f4d489137d3e4bd863e20  2906b810c7d4411798c6938adc9daaa5   \n",
       "\n",
       "       time    age    income  days_as_member    F    M    O  reward  \\\n",
       "19018  2778  125.0  335000.0          9450.0  5.0  0.0  0.0    10.0   \n",
       "3283   1758  156.0  297000.0          5700.0  3.0  0.0  0.0    30.0   \n",
       "37871   822  126.0  112000.0          3592.0  0.0  2.0  0.0     6.0   \n",
       "28430  1290  174.0  174000.0          5721.0  3.0  0.0  0.0    15.0   \n",
       "43616  2244  170.0  230000.0         12090.0  5.0  0.0  0.0    10.0   \n",
       "\n",
       "       difficulty  duration  email  mobile  social  web  offer_completed  \\\n",
       "19018        50.0      50.0    5.0     5.0     5.0  5.0                1   \n",
       "3283         30.0      21.0    3.0     3.0     3.0  0.0                1   \n",
       "37871        14.0      14.0    2.0     2.0     2.0  2.0                0   \n",
       "28430        60.0      30.0    3.0     0.0     0.0  3.0                1   \n",
       "43616        50.0      35.0    5.0     5.0     0.0  5.0                2   \n",
       "\n",
       "       offer_viewed  \n",
       "19018             2  \n",
       "3283              1  \n",
       "37871             1  \n",
       "28430             1  \n",
       "43616             1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offer_complete_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'offer_completed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/wsl_repos/udacity_starbucks_rewards/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/wsl_repos/udacity_starbucks_rewards/venv/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/wsl_repos/udacity_starbucks_rewards/venv/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'offer_completed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mselect_dtypes(include\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mfloat64\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mint64\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     20\u001b[0m \u001b[39m# make 'offer_completed' the last column\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m targetcol \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mpop(\u001b[39m'\u001b[39;49m\u001b[39moffer_completed\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     22\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39moffer_completed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m targetcol\n\u001b[1;32m     24\u001b[0m \u001b[39m# Split the dataset into train and test sets\u001b[39;00m\n",
      "File \u001b[0;32m~/wsl_repos/udacity_starbucks_rewards/venv/lib/python3.10/site-packages/pandas/core/frame.py:5682\u001b[0m, in \u001b[0;36mDataFrame.pop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   5641\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpop\u001b[39m(\u001b[39mself\u001b[39m, item: Hashable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series:\n\u001b[1;32m   5642\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5643\u001b[0m \u001b[39m    Return item and drop from frame. Raise KeyError if not found.\u001b[39;00m\n\u001b[1;32m   5644\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5680\u001b[0m \u001b[39m    3  monkey        NaN\u001b[39;00m\n\u001b[1;32m   5681\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5682\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpop(item\u001b[39m=\u001b[39;49mitem)\n",
      "File \u001b[0;32m~/wsl_repos/udacity_starbucks_rewards/venv/lib/python3.10/site-packages/pandas/core/generic.py:923\u001b[0m, in \u001b[0;36mNDFrame.pop\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpop\u001b[39m(\u001b[39mself\u001b[39m, item: Hashable) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m Any:\n\u001b[0;32m--> 923\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m[item]\n\u001b[1;32m    924\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m[item]\n\u001b[1;32m    926\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/wsl_repos/udacity_starbucks_rewards/venv/lib/python3.10/site-packages/pandas/core/frame.py:3805\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3804\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3805\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3806\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3807\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/wsl_repos/udacity_starbucks_rewards/venv/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'offer_completed'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Load the dataset\n",
    "data = offer_complete_df\n",
    "\n",
    "# drop the user_id, offer_id, time columns\n",
    "# and all non numeric columns\n",
    "data = data.drop(['user_id', 'offer_id', 'time'], axis=1)\n",
    "\n",
    "# drop all non numeric columns\n",
    "data = data.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# make 'offer_completed' the last column\n",
    "targetcol = data.pop('offer_completed')\n",
    "data['offer_completed'] = targetcol\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.2, random_state=42)\n",
    "\n",
    "# # Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the XGBRegressor model\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Perform Recursive Feature Elimination (RFE)\n",
    "rfe = RFE(estimator=xgb, n_features_to_select=10, step=1)\n",
    "rfe.fit(X_train, y_train)\n",
    "\n",
    "# Select the important features from the data\n",
    "X_train_selected = rfe.transform(X_train)\n",
    "X_test_selected = rfe.transform(X_test)\n",
    "\n",
    "# Print the selected features\n",
    "selected_features = X_train.columns[rfe.support_]\n",
    "# info.logger.info(\"Selected features: \", list(selected_features))\n",
    "print(\"Selected features: \", list(selected_features))\n",
    "\n",
    "# Train the XGBRegressor model with selected features\n",
    "xgb_selected = XGBRegressor()\n",
    "xgb_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on the test set using the model with selected features\n",
    "y_pred = xgb_selected.predict(X_test_selected)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('XGBRegressor R^2:', r2)\n",
    "print('XGBRegressor MSE:', mse)\n",
    "print('XGBRegressor RMSE:', rmse)\n",
    "print('XGBRegressor MAE:', mae)\n",
    "\n",
    "# Print the feature importance\n",
    "importance = xgb_selected.feature_importances_\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %s, Score: %.5f' % (selected_features[i],v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'selected_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# write feature importance to a dataframe\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m feature_importance \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\u001b[39m'\u001b[39m\u001b[39mfeature\u001b[39m\u001b[39m'\u001b[39m: selected_features, \u001b[39m'\u001b[39m\u001b[39mimportance\u001b[39m\u001b[39m'\u001b[39m: importance})\n\u001b[1;32m      3\u001b[0m feature_importance \u001b[39m=\u001b[39m feature_importance\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mimportance\u001b[39m\u001b[39m'\u001b[39m, ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m feature_importance\n",
      "\u001b[0;31mNameError\u001b[0m: name 'selected_features' is not defined"
     ]
    }
   ],
   "source": [
    "# write feature importance to a dataframe\n",
    "feature_importance = pd.DataFrame({'feature': selected_features, 'importance': importance})\n",
    "feature_importance = feature_importance.sort_values(by='importance', ascending=False)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Load the dataset\n",
    "data = offer_complete_df\n",
    "\n",
    "# drop the user_id, offer_id, time columns\n",
    "# and all non numeric columns\n",
    "data = data.drop(['user_id', 'offer_id', 'time'], axis=1)\n",
    "\n",
    "# drop all non numeric columns\n",
    "data = data.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# make 'offer_completed' the last column\n",
    "targetcol = data.pop('offer_completed')\n",
    "data['offer_completed'] = targetcol\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.iloc[:,:-1], data.iloc[:,-1], test_size=0.2, random_state=42)\n",
    "\n",
    "# # Scale the data\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the XGBClassifier model\n",
    "xgb = XGBRegressor()\n",
    "\n",
    "# Train the XGBClassifier model\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Feature selection using XGBClassifier\n",
    "selection = SelectFromModel(xgb, threshold='median')\n",
    "selection.fit(X_train, y_train)\n",
    "\n",
    "# Print the indices of the selected features\n",
    "selected_features = selection.get_support(indices=True)\n",
    "# print('Selected features:', selected_features)\n",
    "# get the column names of the selected features\n",
    "selected_features = X_train.columns[selected_features]\n",
    "print('Selected features:')\n",
    "print('\\n'.join(list(selected_features)))\n",
    "\n",
    "# Select the important features from the data\n",
    "X_train_selected = selection.transform(X_train)\n",
    "X_test_selected = selection.transform(X_test)\n",
    "\n",
    "\n",
    "# Train the XGBRegressor model with selected features\n",
    "xgb_selected = XGBRegressor()\n",
    "xgb_selected.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on the test set using the model with selected features\n",
    "y_pred = xgb_selected.predict(X_test_selected)\n",
    "\n",
    "# Calculate the accuracy score\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('XGBRegressor R^2:', r2)\n",
    "print('XGBRegressor MSE:', mse)\n",
    "print('XGBRegressor MAE:', mae)\n",
    "\n",
    "print(len(selected_features))\n",
    "print(len(xgb.feature_importances_))\n",
    "\n",
    "# Print the feature importance\n",
    "importance = xgb_selected.feature_importances_\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %s, Score: %.5f' % (selected_features[i],v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write feature importance to a dataframe\n",
    "feature_importance = pd.DataFrame({'feature': selected_features, 'importance': importance})\n",
    "feature_importance = feature_importance.sort_values(by='importance', ascending=False)\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# plot the feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
